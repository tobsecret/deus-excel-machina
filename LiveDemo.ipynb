{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas      0.20.3\n",
      "numpy       1.11.3\n",
      "re          2.2.1\n",
      "2018-02-15 \n",
      "\n",
      "CPython 3.5.4\n",
      "IPython 6.1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%load_ext watermark\n",
    "%watermark -iv -v -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prevention is the best treatment\n",
    "The easiest way of dealing with terribly formatted, poorly filled in spreadsheets, is to provide our collaborators with a sample spreadsheet with some rows already filled in by us with some dummy information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas comes with many different parsers, making our life a lot easier - luckily one of them handles excel files. The data we are dealing with here are modified from an original spreadsheet from a clinician, handed to one of my professors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfile = pd.ExcelFile('./terrible_spreadsheet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Plate 1',\n",
       " 'Plate 2',\n",
       " 'Plate 3',\n",
       " 'Plate 4',\n",
       " 'Plate 5',\n",
       " 'Plate6',\n",
       " 'Plate7',\n",
       " 'Plate8',\n",
       " 'Plate9',\n",
       " 'Plate10',\n",
       " 'Plate11']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstsheet = excelfile.sheet_names[0]\n",
    "excelfile.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 54)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = pd.read_excel(excelfile, sheetname=firstsheet, header=1)\n",
    "ff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our life easier, we want to read all worksheets from the spreadsheet into a single DataFrame. To keep track which row came from which worksheet, we will additionally incorporate a column with the name `sheet` into each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_excel(excelfile, sheetname=sheet, header=1).assign(sheet=sheet)\n",
    "                for sheet in excelfile.sheet_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience in our further analysis, we want column names to only consist of numbers, letters or the underscore character. That is because columns for which this is true can be accessed via the `.`, so to access `column1`, we would write `df.column1`. We will use a regular expression or short regex to do this. For more info you can look at the slides from [Al Sweigart's talk \"Yes it's time to learn regular expressions\"](http://bitly.com/yesregex) or watch the talk itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ABA', 'Age', 'BSA', 'Betatoxin', 'Exoprotein ext', 'Gender',\n",
       "       'Glom.extract', 'HLA', 'HLA -2', 'HLA-1', 'HSA', 'Hemolysin gamma A',\n",
       "       'Hemolysin gamma B', 'Hemolysin gamma C', 'Hospital ', 'LDL',\n",
       "       'LukAB(Lab)', 'LukAB(cc30)', 'LukD', 'LukE', 'LukF-PV', 'LukS-PV',\n",
       "       'PC-12', 'PC16', 'PC4', 'PLY', 'PNAG', 'PSM 4variant', 'PSMalpha2',\n",
       "       'PSMalpha3', 'Pn CWPS', 'Pn PS12', 'Pn PS23', 'Rabbit IgG',\n",
       "       'S.Pyogenese arcA', 'SEB', 'SEB.1', 'SEG', 'SEI', 'SEM', 'SEN', 'SEO',\n",
       "       'SEU', 'SP', 'Sample ID', 'SpA domD5-WT', 'SpA domD5FcNull',\n",
       "       'Tetanus Toxoid', 'Tetanus Toxoid.1', 'cytoplasmic ext', 'hIgA', 'hIgG',\n",
       "       'psmalpah4', 'sheet', 'surface protein ext'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colcleaningregex = re.compile(r'[^\\w]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcols = [colcleaningregex.sub('_', col.strip()) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(oldcols)-len(oldcols.unique()),\n",
    "     len(newcols)-len(np.unique(newcols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = newcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of empty columns & clean index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes people include columns in their DataFrame that are completely useless for analysis, as they are completely empty. If we expect more data in the forms of additional spreadsheets to require our processing in the future, we would leave them in but since that is not the case here, we can simply delete those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ABA                     True\n",
       "Age                     True\n",
       "BSA                     True\n",
       "Betatoxin               True\n",
       "Exoprotein_ext          True\n",
       "Gender                  True\n",
       "Glom_extract            True\n",
       "HLA                     True\n",
       "HLA__2                  True\n",
       "HLA_1                   True\n",
       "HSA                     True\n",
       "Hemolysin_gamma_A       True\n",
       "Hemolysin_gamma_B       True\n",
       "Hemolysin_gamma_C       True\n",
       "Hospital                True\n",
       "LDL                     True\n",
       "LukAB_Lab_              True\n",
       "LukAB_cc30_             True\n",
       "LukD                    True\n",
       "LukE                    True\n",
       "LukF_PV                 True\n",
       "LukS_PV                 True\n",
       "PC_12                   True\n",
       "PC16                    True\n",
       "PC4                     True\n",
       "PLY                     True\n",
       "PNAG                    True\n",
       "PSM_4variant            True\n",
       "PSMalpha2               True\n",
       "PSMalpha3               True\n",
       "Pn_CWPS                 True\n",
       "Pn_PS12                 True\n",
       "Pn_PS23                 True\n",
       "Rabbit_IgG              True\n",
       "S_Pyogenese_arcA        True\n",
       "SEB                     True\n",
       "SEB_1                   True\n",
       "SEG                     True\n",
       "SEI                     True\n",
       "SEM                     True\n",
       "SEN                     True\n",
       "SEO                     True\n",
       "SEU                     True\n",
       "SP                      True\n",
       "Sample_ID               True\n",
       "SpA_domD5_WT            True\n",
       "SpA_domD5FcNull         True\n",
       "Tetanus_Toxoid          True\n",
       "Tetanus_Toxoid_1       False\n",
       "cytoplasmic_ext         True\n",
       "hIgA                    True\n",
       "hIgG                    True\n",
       "psmalpah4               True\n",
       "sheet                   True\n",
       "surface_protein_ext     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.notnull().any()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill *Hospital*, *Age* and *Gender* columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Hospital`, `Age` and `Gender` columns are only filled in every couple of lines. We want to fill in the blanks. Since we already have everything loaded into one DataFrame, we have to use a groupby operation. Otherwise the last info in these columns from one sheet can transfer to the empty rows in the beginning of the next sheet, which we do not want. In order to be able to use apply on a groupby object, we need to `reset_index` because our DataFrame contains duplicate indices which is prohibited in groupby-apply operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True) #required in order for the groupby-apply to work\n",
    "df.loc[:, ['Hospital', 'Age', 'Gender']] = df.groupby('sheet').apply(\n",
    "    lambda x: x.loc[:, ['Hospital', 'Age', 'Gender']].fillna(method='ffill')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hospital1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hospital1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hospital1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hospital1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospital1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hospital   Age Gender\n",
       "10  hospital1  60.0      M\n",
       "11  hospital1  60.0      M\n",
       "12  hospital1  60.0      M\n",
       "13  hospital1  60.0      M\n",
       "14  hospital1  60.0      M"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, ['Hospital', 'Age', 'Gender']].iloc[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract *PatientID*, *Visit* and *Dilution* from *Sample_ID*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three pieces of information are stored in the `Sample_ID` column - the `PatientID`, the `Visit` and the `Dilution`. \n",
    "The `PatientID` is a five digit number, the `Visit` comes in between the `PatientID` and the `Dilution` and the `Dilution` is composed of 1s and 0s and is at the end of the `Sample_ID` string.\n",
    "Each of these can be missing in a row. We want to use a regular expression in order to extract this info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        StringMethods\n",
       "\u001b[1;31mString form:\u001b[0m <pandas.core.strings.StringMethods object at 0x00000000090F75F8>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\tobias\\miniconda3\\envs\\pdsh_mod\\lib\\site-packages\\pandas\\core\\strings.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Vectorized string functions for Series and Index. NAs stay NA unless\n",
       "handled otherwise by a particular method. Patterned after Python's string\n",
       "methods, with some inspiration from R's stringr package.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> s.str.split('_')\n",
       ">>> s.str.replace('_', '')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Sample_ID.str?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'V1', 'V2', 'V3', 'v1', '', 'GS2', 'GS1', 'JM', 'VANDER'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.Sample_ID.str.extract(r'.*\\s(?P<Dilution>1[0]+)', expand=True)\n",
    "df.Sample_ID.str.extract(r'\\s(?P<Visit>[^\\s]*)\\s', expand=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Dilution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23234</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23234</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23234</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23234</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23234</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23234</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23234</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23234</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28531</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28531</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>28531</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28531</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28531</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28531</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28531</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>28531</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28729</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>28729</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28729</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28729</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28729</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28729</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28729</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>59302</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>59302</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>59302</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>59302</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>59302</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>59302</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>15439</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>15439</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>15439</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>15439</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>15439</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>15439</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>15439</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>15439</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>14127</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>14127</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>14127</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>14127</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>14127</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>14127</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>14127</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>14127</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>10732</td>\n",
       "      <td>V1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>10732</td>\n",
       "      <td>V1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>10732</td>\n",
       "      <td>V1</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>10732</td>\n",
       "      <td>V1</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>10732</td>\n",
       "      <td>V2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>10732</td>\n",
       "      <td>V2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>10732</td>\n",
       "      <td>V2</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>10732</td>\n",
       "      <td>V2</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PatientID Visit  Dilution\n",
       "0         NaN   NaN        10\n",
       "1         NaN   NaN       100\n",
       "2         NaN   NaN      1000\n",
       "3         NaN   NaN     10000\n",
       "4         NaN   NaN    100000\n",
       "5         NaN   NaN   1000000\n",
       "6         NaN   NaN  10000000\n",
       "7       23234    V1       100\n",
       "8       23234    V1      1000\n",
       "9       23234    V1     10000\n",
       "10      23234    V1    100000\n",
       "11      23234    V2       100\n",
       "12      23234    V2      1000\n",
       "13      23234    V2     10000\n",
       "14      23234    V2    100000\n",
       "15      28531    V1       100\n",
       "16      28531    V1      1000\n",
       "17      28531    V1     10000\n",
       "18      28531    V1    100000\n",
       "19      28531    V2       100\n",
       "20      28531    V2      1000\n",
       "21      28531    V2     10000\n",
       "22      28531    V2    100000\n",
       "23      28729    V1       100\n",
       "24      28729    V1      1000\n",
       "25      28729    V1     10000\n",
       "26      28729    V1    100000\n",
       "27      28729    V2       100\n",
       "28      28729    V2      1000\n",
       "29      28729    V2     10000\n",
       "..        ...   ...       ...\n",
       "440     59302    V1     10000\n",
       "441     59302    V1    100000\n",
       "442     59302    V2       100\n",
       "443     59302    V2      1000\n",
       "444     59302    V2     10000\n",
       "445     59302    V2    100000\n",
       "446     15439    V1       100\n",
       "447     15439    V1      1000\n",
       "448     15439    V1     10000\n",
       "449     15439    V1    100000\n",
       "450     15439    V2       100\n",
       "451     15439    V2      1000\n",
       "452     15439    V2     10000\n",
       "453     15439    V2    100000\n",
       "454     14127    V1       100\n",
       "455     14127    V1      1000\n",
       "456     14127    V1     10000\n",
       "457     14127    V1    100000\n",
       "458     14127    V2       100\n",
       "459     14127    V2      1000\n",
       "460     14127    V2     10000\n",
       "461     14127    V2    100000\n",
       "462     10732    V1       100\n",
       "463     10732    V1      1000\n",
       "464     10732    V1     10000\n",
       "465     10732    V1    100000\n",
       "466     10732    V2       100\n",
       "467     10732    V2      1000\n",
       "468     10732    V2     10000\n",
       "469     10732    V2    100000\n",
       "\n",
       "[470 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df.Sample_ID.str.extract(\n",
    "    r'(?P<PatientID>\\d{5})?\\s*(?P<Visit>[^\\s]+\\d)?\\s+(?P<Dilution>1[0]+)?\\s*$', \n",
    "                         expand=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'V1', 'V2', 'V3', 'v1', 'GS2', 'GS1'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.Visit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '23234', '28531', '28729', '33142', '35568', '62901', '52950',\n",
       "       '57756', '48689', '62129', '62300', '62900', '17588', '15363',\n",
       "       '59707', '64779', '67029', '77612', '78202', '83700', '84504',\n",
       "       '99361', '92827', '93954', '94232', '99382', '11825', '99624',\n",
       "       '99682', '27764', '44989', '27986', '37422', '46713', '59302',\n",
       "       '15439', '14127', '10732'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.PatientID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '100', '1000', '10000', '100000', '1000000', '10000000', nan], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.Dilution.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PDSH_mod]",
   "language": "python",
   "name": "conda-env-PDSH_mod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
